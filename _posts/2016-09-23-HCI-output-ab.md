---
layout: post
title: 字幕组论文总结1
categories: HCI
description: 字幕组论文总结
keywords: HCI EyeTracking
---



 # 总结

 ## 「Improving Video Captioning for Deaf and Hearing-impaired People Based on Eye Movement and Attention Overload」


>INTRODUCTION

1. 目前聋人和听力有障碍的人只能依赖字幕获取电视中的声音信息，
而大部分字幕都是预先生成好的，对于直播等不能预先生成字幕的情况而言，我们需要实时字幕。
但是，目前，实时字幕存在着许多弊端，比如: a.生成质量不高 b.转录的延时
所以，对于听力有障碍的认识，预先处理好的字幕比实时字幕要好的多。
嗯，但是实时字幕还是相当有前景的。

2. 用户观看视频需要结合视频内容和字幕，我们通过实验来观察听力障碍人士的观看策略，即，对视频内容本身和字幕的注意力的分配
实验发现这类人群有比常人更好的视觉技能。
而且，实验发现，有时阅读字幕严重妨碍观看。
通过眼球的观看轨迹可以获得用户的观看策略。以此为出发点来找到适合听力障碍人士的实时字幕的解决方案。

3.  首先，我们将视觉的注意分为 a.视频内容的注意 b.字幕的注意
其次，我们将观看者出现视频上的信息过多过饱和以至于不能及时处理的现象成为 Attention overload。
对于眼动分析，我们也只在意两个区域:  (i) Static Regions Of Interest (ROI) 主要是字幕区域
, (ii) Dynamic ROI 主要是人脸和移动物体的区域

>TECHNICAL BACKGROUND

1. 使用 pupil-center-corneal-reflection 系统来跟踪眼动，当然，分析区域在两个ROI里。先来看眼动的2个动作: 聚焦和扫视
  + 怎么判断动作是聚焦还是扫视
判断某时刻是否聚焦有很多算法，实验中采用如果视线在某点停留250ms，并且 (their distance with respect to the centroid corresponds to 0.75 degree of viewing angle 不太懂。。。)
就判断为一个聚焦。
  + 获得关注字幕与视频内容在整个观看过程中的比例

2. Scanpath 扫描路径
  + 我们的目标: 我们希望了解听力障碍人士是否共有一个特殊的观看策略，这样对我们改进字幕位置有重要作用。
  + 事先的预想: 我们将每一个 ROI 标注上一个 ascii 码，不是 ROI 的区域设为 null，由此我们可以获得观看者的观看序列。
得到所有观看者的序列之后，我们分析它们的相似性，怎么分析 ascii 序列的相似性呢？ 实验中使用了 Levenshtein distance
它能找出一个序列通过删除，替换，插入得到另一个序列的最小步数，另外，我们对步数进行正规化，便于比较。
  + 现实: 实验人数过少，没法比。替代方案: 先对观看者进行回忆测试，表现最好的一位观看者的序列被标为 「best」，最差的被标为 「worst」，
其他人的数据只要和这两个序列比较就好了，我们可以得到它们是否靠近哪一个。

3. 运动图像和 Dynamic ROI
  + 首先，字幕不应放在运动图像上，这可能会隐藏重要的视频信息。
  + 检测运动图像和人脸，不让字幕出现在上面，最后找一个适合的地方放置字幕。 如图:
![figure1](/images/posts/hci/hci1.png)

>METHODOLOGY

1. 实验发现，听力障碍人士不但对快速字幕有理解问题，还对一些场景激烈的镜头如: 暴乱，战争，竞技比赛等也出现了 Attention overload。
由此，我们想到，字幕速度应该和运动图像的 ( 激烈程度？ 不知道怎么翻译。。。 ) 有关。

>CONCLUSION

1. 字幕阅读
  + 事实上听力障碍人士在阅读字幕和观看内容上有着不同的观看策略，貌似并没有一个统一的规律，而且时间的分配也会随着画面的 ( 激烈程度？) 和字幕的速度而改变。
  + 我们猜测人脸和移动物体是最吸引人注意的，事实上也确实是这样的。而且听力残障人士会比听力正常人士看脸更多。但如果这个人之前出现过，或此时是这人的特写镜头，这种关注会下降。
比如说，如果出现一个新人，他的字幕就应该在该人下方，但如果这是一张老面孔，那么字幕就可以不用挪动位置，支持快速阅读模式。
  + 将字幕放在 ROI 附近可能是一个好的选择。


